#!/bin/bash
#BSUB -J feat_sel[1-32]              # Job array name and job indexes
#BSUB -n 10                          # Number of tasks
#BSUB -R "span[hosts=1]"             # Allocate all tasks in 1 host
#BSUB -q short                       # Select queue
#BSUB -R "rusage[mem=1GB]"
#BSUB -o output-featSelectionMulticlass-%J.out              # Output file
#BSUB -e output-featSelectionMulticlass-%J.err              # Error file

# Run here appropriate module load statements for your cluster environment
# module load ...

# Parameters
dataset_info=/path/to/datasets.csv file
project_path=/path/to/experiment/folder
# Validation indices to process (all will run in parallel)
n_features=50
beam=beam1
shuffle=False
random_state=42
date=15042024
rfe_step=0.05
n_jobs=-1
indx=({1..100})

# Indicate which file to process
# Note: Manual now -> Switch to LSF array
idx=$LSB_JOBINDEX-1
data_path=$project_path/Results/$beam

# Set command-line arguments

test_indx=${indx[$idx]}
echo "test_index: $test_indx"

# Call the Python script
python feature_selection_multiclass.py \
        --dataset_info $dataset_info \
	--data_path $data_path\
	--test_indx $test_indx \
	--beam $beam\
	--n_features $n_features\
	--random_state $random_state\
	--shuffle $shuffle\
	--date $date\
	--rfe_step $rfe_step\
	--n_jobs $n_jobs
	