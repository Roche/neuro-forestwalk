#!/bin/bash
#BSUB -J multiclass[1-3]            # Job array name and job indexes
#BSUB -n 1                          # Number of tasks
#BSUB -R "span[hosts=1]"            # Allocate all tasks in 1 host
#BSUB -q short                      # Select queue
#BSUB -R "rusage[mem=1GB]"
#BSUB -o output-%J-classificationMulticlass.out              # Output file
#BSUB -e output-%J-classificationMulticlass.err              # Error file

# Run here appropriate module load statements for your cluster environment
# module load ...

# Parameters
project_path=/path/to/experiment/folder
# Videos to process (all will run in parallel)
beams=(beam1 beam2 beam3)
shuffle=False
date=15042024_5multiclass
n_features=50
n_jobs=-1

# Indicate which file to process
# Note: Manual now -> Switch to LSF array
idx=$LSB_JOBINDEX-1

# Set command-line arguments
df_data=$project_path/Results/${beams[$idx]}/feature_df.csv
folder_path=$project_path/Results/${beams[$idx]}
beam=${beams[$idx]}

echo "test_index: $test_indx"

# Call the Python script
python classification_multiclass.py \
        --df_data $df_data \
	--folder_path $folder_path \
       	--beam $beam \
	--shuffle $shuffle\
	--date $date\
	--n_features $n_features\
	--n_jobs $n_jobs
